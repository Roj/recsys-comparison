{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recsys Data Analysis\n",
    "\n",
    "This notebook analyzes the results of different datasets and different recomendation algorithms in order to stablish a baseline for Lenskit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to import our libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We use the following datasets for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LastFM\n",
    "\n",
    "- Users: 1892 users\n",
    "- Items: 17632 artists\n",
    "\n",
    "This dataset contains 92.834 user-artist relations. The weight of the graph’s edges represents amount of plays. We considered these weights as ratings.\n",
    "\n",
    "In this iteration of the analysis we did not normalize the numbers into a [1,5] scale. It can be done by classifying each relation into its respective quintile. This approach, however, has the drawback of discretizing something that is very continuous; for example, relationships that are on the upper scale of a quintile are qualitatively similar to those on the lower scale of the next quintile, but we are losing that information. Another consequence (which may not be a problem, but it is an interesting result nonetheless) is that each class will have exactly the same amount of members (relationships). As datasets that include a normal rating system often do not have this property, it may be appealing to run the algorithms on this normalized dataset.\n",
    "\n",
    "Another approach is inspired by the Mahalanobis distance; in essence, calculate the mean of the ratings and for each rating calculate how many standard deviations it strays from the mean. Those that are deviated to higher values are assigned a value near to 5 and ratings that deviate from the mean but by being lower are assigned values near to 1. This might have the effect of having ratings form a normal distribution, which is also not common in “true” rating datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movielens-1k\n",
    "- Users: 943 users \n",
    "- Items: 1682 movies\n",
    "\n",
    "This dataset contains 100.000 user-movie relations. Each relation represents the evaluation of a movie by a user (in a scale from 1 to 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jester\n",
    "\n",
    "\n",
    "- Users: 73.495 users\n",
    "- Items: 100 jokes\n",
    "\n",
    "This dataset contains 4.1 million of user-joke relations. Each relation represents the evaluation of a movie by a user (in a scale from -10.0 to 10.0). As the scale is different to the used in Movielens, we decided to normalized the evaluations to a scale of [1,5].\n",
    "This dataset is really unique as the number of items, in this case jokes, is only 100. One of the consequences of this property is that the user-item matrix is not as sparse as it normally is elsewhere. It wouldn’t be unusual for one user to have rated a majority of the items; in contrast, this would have been unthinkable in other datasets like MovieLens or Amazon-Books. The quantitative characterization of this dataset (and the rest) remains as future work (see conclusions for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookcrossing\n",
    "\n",
    "- Users: 278.858 users\n",
    "- Items: 271.379 books\n",
    "\n",
    "This dataset contains 1.149.780 of user-book relations. Each relation represents the evaluation of a book by a user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The results for each dataset is stored in a `csv` file.\n",
    "We ran each algorithm 5 times since we used 5-fold cross-validation.  What we want to do next is compute the average value of each metric for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BuildTime</th>\n",
       "      <th>TestTime</th>\n",
       "      <th>RMSE.ByUser</th>\n",
       "      <th>RMSE.ByRating</th>\n",
       "      <th>Predict.nDCG</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">jester</th>\n",
       "      <th>Custom</th>\n",
       "      <td>0.7688</td>\n",
       "      <td>3.6016</td>\n",
       "      <td>0.826559</td>\n",
       "      <td>0.876547</td>\n",
       "      <td>0.944487</td>\n",
       "      <td>0.626766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunkSVD</th>\n",
       "      <td>275.6342</td>\n",
       "      <td>5.4392</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.820905</td>\n",
       "      <td>0.953069</td>\n",
       "      <td>0.613710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemItem</th>\n",
       "      <td>6.8920</td>\n",
       "      <td>13.6160</td>\n",
       "      <td>0.790791</td>\n",
       "      <td>0.834246</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>0.618007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PersMean</th>\n",
       "      <td>0.2014</td>\n",
       "      <td>4.6386</td>\n",
       "      <td>0.826559</td>\n",
       "      <td>0.876547</td>\n",
       "      <td>0.944487</td>\n",
       "      <td>0.626754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserUser</th>\n",
       "      <td>0.0562</td>\n",
       "      <td>46752.3962</td>\n",
       "      <td>0.796242</td>\n",
       "      <td>0.837172</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.715006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lastfm</th>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0652</td>\n",
       "      <td>3.9202</td>\n",
       "      <td>1225.316632</td>\n",
       "      <td>3052.545397</td>\n",
       "      <td>0.811768</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunkSVD</th>\n",
       "      <td>6.0048</td>\n",
       "      <td>11.1364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754774</td>\n",
       "      <td>0.004653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemItem</th>\n",
       "      <td>4.3300</td>\n",
       "      <td>22.1684</td>\n",
       "      <td>1455.425755</td>\n",
       "      <td>4469.689135</td>\n",
       "      <td>0.734481</td>\n",
       "      <td>0.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PersMean</th>\n",
       "      <td>0.0980</td>\n",
       "      <td>8.5226</td>\n",
       "      <td>1225.316632</td>\n",
       "      <td>3052.545397</td>\n",
       "      <td>0.811768</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserUser</th>\n",
       "      <td>0.0660</td>\n",
       "      <td>20.7732</td>\n",
       "      <td>1226.077364</td>\n",
       "      <td>3251.001417</td>\n",
       "      <td>0.743537</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">movielens</th>\n",
       "      <th>Custom</th>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.920828</td>\n",
       "      <td>0.938236</td>\n",
       "      <td>0.949941</td>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FunkSVD</th>\n",
       "      <td>17.7272</td>\n",
       "      <td>1.2894</td>\n",
       "      <td>0.912880</td>\n",
       "      <td>0.927017</td>\n",
       "      <td>0.951345</td>\n",
       "      <td>0.004229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemItem</th>\n",
       "      <td>9.3392</td>\n",
       "      <td>22.4264</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>0.896983</td>\n",
       "      <td>0.955260</td>\n",
       "      <td>0.095015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PersMean</th>\n",
       "      <td>0.2258</td>\n",
       "      <td>1.3900</td>\n",
       "      <td>0.920828</td>\n",
       "      <td>0.938236</td>\n",
       "      <td>0.949941</td>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserUser</th>\n",
       "      <td>0.1492</td>\n",
       "      <td>30.6152</td>\n",
       "      <td>0.915197</td>\n",
       "      <td>0.924923</td>\n",
       "      <td>0.953311</td>\n",
       "      <td>0.003774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BuildTime    TestTime  RMSE.ByUser  RMSE.ByRating  \\\n",
       "Dataset   Algorithm                                                      \n",
       "jester    Custom        0.7688      3.6016     0.826559       0.876547   \n",
       "          FunkSVD     275.6342      5.4392     0.777133       0.820905   \n",
       "          ItemItem      6.8920     13.6160     0.790791       0.834246   \n",
       "          PersMean      0.2014      4.6386     0.826559       0.876547   \n",
       "          UserUser      0.0562  46752.3962     0.796242       0.837172   \n",
       "lastfm    Custom        0.0652      3.9202  1225.316632    3052.545397   \n",
       "          FunkSVD       6.0048     11.1364          NaN            NaN   \n",
       "          ItemItem      4.3300     22.1684  1455.425755    4469.689135   \n",
       "          PersMean      0.0980      8.5226  1225.316632    3052.545397   \n",
       "          UserUser      0.0660     20.7732  1226.077364    3251.001417   \n",
       "movielens Custom        0.0924      0.7654     0.920828       0.938236   \n",
       "          FunkSVD      17.7272      1.2894     0.912880       0.927017   \n",
       "          ItemItem      9.3392     22.4264     0.890329       0.896983   \n",
       "          PersMean      0.2258      1.3900     0.920828       0.938236   \n",
       "          UserUser      0.1492     30.6152     0.915197       0.924923   \n",
       "\n",
       "                     Predict.nDCG       MRR  \n",
       "Dataset   Algorithm                          \n",
       "jester    Custom         0.944487  0.626766  \n",
       "          FunkSVD        0.953069  0.613710  \n",
       "          ItemItem       0.950978  0.618007  \n",
       "          PersMean       0.944487  0.626754  \n",
       "          UserUser       0.951187  0.715006  \n",
       "lastfm    Custom         0.811768  0.000650  \n",
       "          FunkSVD        0.754774  0.004653  \n",
       "          ItemItem       0.734481  0.001663  \n",
       "          PersMean       0.811768  0.000650  \n",
       "          UserUser       0.743537  0.001729  \n",
       "movielens Custom         0.949941  0.002643  \n",
       "          FunkSVD        0.951345  0.004229  \n",
       "          ItemItem       0.955260  0.095015  \n",
       "          PersMean       0.949941  0.002643  \n",
       "          UserUser       0.953311  0.003774  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = ['lastfm','movielens','jester']\n",
    "results = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    aux = pd.read_csv('data-analysis/results/'+dataset+'/eval-results.csv')\n",
    "    aux['Dataset'] = dataset\n",
    "    if results.empty : results = aux\n",
    "    else: results = results.append(aux)\n",
    "\n",
    "agg_results = results.drop(['Partition'], axis=1).groupby(['Dataset','Algorithm']).mean()\n",
    "agg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "### RMSE\n",
    "\n",
    "RMSE reflects the difference between the real values and those predicted by the algorithm. It is calculated in two ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "raw_mimetype": "text/latex",
    "scrolled": true
   },
   "source": [
    "- Grouped by user: RMSE.byUser \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\displaystyle\\sum_{\\forall u\\in U}\\sqrt{\\frac{\\displaystyle\\sum_{\\forall r \\in R} err_{ru}^2}{|R_u|}}}{|U|}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Globally: RMSE.byRating\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sqrt{\\frac{\\displaystyle\\sum_{\\forall u \\in U}\\displaystyle\\sum_{\\forall r \\in R} err_{ru}^2}{|R|}}\n",
    "\\end{equation}\n",
    "\n",
    "In general, both ways gives similar results.\n",
    "\n",
    "In the case of LastFM, while grouping by users, the results are approximately a third of those obtained using the Global expression. And it is interesting to see that the values are enormous in comparison to those obtained with Movielens and Jester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR\n",
    "\n",
    "This metric measures the ranking quality of the algorithm. This metric gives particular good results for Jester. That seems to be caused by the reduced number of items in the dataset (only 100 jokes). We could say that it is easier to \"guess\" the correct ranking in Jester than in the other datasets because of it has less items to order. Also it’s curious that MRR result for Movielens using CF item-item are approximately 40 times better than the outcome for the same metric, the same dataset, but with other algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nDCG\n",
    "\n",
    "nDCG also reflects the ranking performance of an algorithm. For Jester and Movielens, we can see that it has a similar behavior to that of MRR. But in LastFM dataset, its worst result coincides with the best results of MRR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "### CF Item-item\n",
    "For the rating evaluations (MRR), CF Item-item is the algorithm with the best performance in LastFM and Movielens. But with Jester it is worse than CF User-user.\n",
    "\n",
    "### PersMean\n",
    "This algorithm has the best RMSE performance for Jester and Movielens, while in LastFM the other algorithms perform better.\n",
    "\n",
    "### CF User-user\n",
    "In general CF User-user has good, but not outstanding, RMSE results with Jester and Movielens. Also, in Jester the best MRR results are obtained by CF User-user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Although we didn’t do enough analysis to deduce solid conclusions, we can see that the behavior of the algorithms with LastFM is notoriously different to the one with the other datasets. This is probably a consequence of the fact that the relation between user-item is not an explicit eval- uation, like in the other datasets, it is the number of times the user listened to the item (artist). Nevertheless, our intention is to perform grid-search, in order to obtained stronger conclusions."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
